{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d7513f-aa87-4528-b529-90b76de0b4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StringType,StructField,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db7f937-4ec5-4e06-8f7e-45b6c4bc8958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/07 13:55:34 WARN Utils: Your hostname, Obinnas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.2.190 instead (on interface en0)\n",
      "23/09/07 13:55:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/07 13:55:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/07 13:55:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName('Sparkdfpractice').getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d3ec1a-a527-4841-afc4-9be6311b4387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Start by creating the schema of the dataframe\n",
    "#Data as list of tuples\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c168e9a5-52b0-4d88-a7cd-efc5535112ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c6488f-6d21-4b06-b60a-b3d159130705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We have defined the schema variable and stated that all fields can be nullable\n",
    "schema = StructType([\n",
    "    StructField(\"Firstname\", StringType(), True),\n",
    "    StructField(\"middlename\", StringType(), True),\n",
    "    StructField(\"Lastname\", StringType(), True),\n",
    "    StructField(\"ID\", StringType(), True),\n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Salary\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0cb055-21ca-4d79-8a3e-ff7b67ae5b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- Lastname: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe and assign the schema\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4201ae39-d703-4a03-aac0-3d3c62b3fcf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|Firstname|middlename|Lastname|ID   |Gender|Salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aef296ce-5913-44f2-a793-a5a404318a39",
   "metadata": {
    "tags": []
   },
   "source": [
    "filepath = \"./testdata/fire-incidents.csv\"\n",
    "\n",
    "fire_df = (spark.read.format(\"csv\")\n",
    "              .option('header',True)\n",
    "              .option('inferSchema',True)\n",
    "              .load(filepath))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "355463ca-96a0-48ca-b310-185022f799cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "fire_df.select(\"IncidentNumber\",\"IncidentDate\",\"City\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709956bd-9995-4487-a840-1ea6d30100cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef230956-e73c-4dc7-8ac4-b2fb7880df0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "fire_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f883af0-de9d-4f32-ab6e-ababb490d267",
   "metadata": {
    "tags": []
   },
   "source": [
    "#saving/writing the dfoutput as a parquet file that can be using on distributed sytems\n",
    "#overwite allows us to overwrite to this file over and over again \n",
    "\n",
    "output_path = \"./data/output/fireincidents\"\n",
    "\n",
    "fire_df.write.format(\"parquet\").mode(\"overwrite\").save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95216b7e-e5ca-45be-956d-f04cef6ca9b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## WORKING WITH STRUCTURED OPERATIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c297b-df0f-46b9-83e1-f8a22b48c443",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reading in the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ce6345-5589-4a0d-9a40-a1bd8a6af8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, FloatType, DateType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a5db5d-edc4-4cd3-bace-5b28d3d3b04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persons_schema = StructType ([\n",
    "    StructField('id',IntegerType(), True),\n",
    "    StructField('first_name',StringType(), True),\n",
    "    StructField('last_name',StringType(), True),\n",
    "    StructField('fav_movies',ArrayType(StringType()), True),\n",
    "    StructField('salary',FloatType(), True),\n",
    "    StructField('image_url',StringType(), True),\n",
    "    StructField('date_of_birth',DateType(), True),\n",
    "    StructField('active',BooleanType(), True)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e62a57-1859-4194-8cbe-a184927bce67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = \"./testdata/persons/persons.json\"\n",
    "\n",
    "persons_df = (spark.read.json(filepath,persons_schema,multiLine=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be28f22-83f4-43da-a8c8-db7a52d5e5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7cae450-2be4-4224-a0c4-336a977c57a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- fav_movies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- salary: float (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acb912be-af3b-42c9-9c9c-06bd95dddf82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+----------------------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "|id |first_name|last_name  |fav_movies                                                                  |salary |image_url                                      |date_of_birth|active|\n",
      "+---+----------+-----------+----------------------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "|1  |Drucy     |Poppy      |[I giorni contati]                                                          |1463.36|http://dummyimage.com/126x166.png/cc0000/ffffff|1991-02-16   |true  |\n",
      "|2  |Emelyne   |Blaza      |[Musketeer, The, Topralli]                                                  |3006.04|http://dummyimage.com/158x106.bmp/cc0000/ffffff|1991-11-02   |false |\n",
      "|3  |Max       |Rettie     |[The Forgotten Space, Make It Happen]                                       |1422.88|http://dummyimage.com/237x140.jpg/ff4444/ffffff|1990-03-03   |false |\n",
      "|4  |Ilario    |Kean       |[Up Close and Personal]                                                     |3561.36|http://dummyimage.com/207x121.jpg/cc0000/ffffff|1987-06-09   |true  |\n",
      "|5  |Toddy     |Drexel     |[Walk in the Clouds, A]                                                     |4934.87|http://dummyimage.com/116x202.png/cc0000/ffffff|1992-10-28   |true  |\n",
      "|6  |Oswald    |Petrolli   |[Wing and the Thigh, The (L'aile ou la cuisse)]                             |1153.23|http://dummyimage.com/137x172.jpg/5fa2dd/ffffff|1986-09-02   |false |\n",
      "|7  |Adrian    |Clarey     |[Walking Tall, Paradise, Hawaiian Style]                                    |1044.73|http://dummyimage.com/244x218.bmp/cc0000/ffffff|1971-08-24   |false |\n",
      "|8  |Dominica  |Goodnow    |[Hearts Divided]                                                            |1147.76|http://dummyimage.com/112x203.jpg/dddddd/000000|1973-08-27   |false |\n",
      "|9  |Emory     |Slocomb    |[Snake and Crane Arts of Shaolin (She hao ba bu), Mala Noche]               |1082.11|http://dummyimage.com/138x226.jpg/cc0000/ffffff|1974-06-08   |true  |\n",
      "|10 |Jeremias  |Bode       |[Farewell to Arms, A]                                                       |3472.63|http://dummyimage.com/243x108.bmp/dddddd/000000|1997-08-02   |true  |\n",
      "|11 |Timothy   |Ervine     |[Land of the Lost, Save the Last Dance, Whispering Corridors (Yeogo Goedam)]|1147.61|http://dummyimage.com/162x184.bmp/5fa2dd/ffffff|1971-06-02   |false |\n",
      "|12 |Leanora   |Gooder     |[It's All About Love, Scooby-Doo! The Mystery Begins]                       |1327.02|http://dummyimage.com/108x237.png/5fa2dd/ffffff|1981-12-17   |false |\n",
      "|13 |Claiborn  |Denham     |[McCullin, Max Payne, Oath, The]                                            |2623.33|http://dummyimage.com/250x200.bmp/5fa2dd/ffffff|1996-03-07   |false |\n",
      "|14 |Ambrosi   |Vidineev   |[Wall Street: Money Never Sleeps, Applause (Applaus), When a Stranger Calls]|4550.88|http://dummyimage.com/232x159.png/5fa2dd/ffffff|1989-07-20   |true  |\n",
      "|15 |Feodor    |Nancekivell|[Monsoon Wedding]                                                           |2218.46|http://dummyimage.com/119x120.bmp/cc0000/ffffff|2000-10-07   |false |\n",
      "|16 |Margaux   |Archbold   |[And Now a Word from Our Sponsor]                                           |1013.75|http://dummyimage.com/229x133.png/5fa2dd/ffffff|1988-07-29   |true  |\n",
      "|17 |Balduin   |Elstone    |[Sisters, The]                                                              |2302.26|http://dummyimage.com/171x173.png/5fa2dd/ffffff|1974-07-20   |false |\n",
      "|18 |Alfie     |Hatliffe   |[Lord of Tears]                                                             |3893.1 |http://dummyimage.com/142x242.png/5fa2dd/ffffff|1989-06-21   |true  |\n",
      "|19 |Lura      |Follis     |[My Life in Pink (Ma vie en rose), Test Pilot, Sin of Madelon Claudet, The] |3331.26|http://dummyimage.com/189x205.bmp/dddddd/000000|1998-11-03   |false |\n",
      "|20 |Maxi      |Cluet      |[All I Want for Christmas]                                                  |4046.46|http://dummyimage.com/110x101.png/cc0000/ffffff|1979-05-06   |false |\n",
      "+---+----------+-----------+----------------------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886f75bc-78f4-415e-910b-f3e2ab24c6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'first_name',\n",
       " 'last_name',\n",
       " 'fav_movies',\n",
       " 'salary',\n",
       " 'image_url',\n",
       " 'date_of_birth',\n",
       " 'active']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968bd52-403c-45a2-9704-f02361e84c8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Columns and Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4002d401-dfa9-400e-a5ec-a7b7f0a8b730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ca4d44c-1927-45ef-9297-0dc1f12e80c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(col(\"first_name\"),col('last_name'),col('date_of_birth')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c450501c-6854-474f-95b4-be5feb4197f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(\"first_name\",'last_name','date_of_birth').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35232c13-138b-4c90-94b8-b889b6935d35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(expr(\"first_name\"),expr('last_name'),expr('date_of_birth')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f77da-6133-409e-9b19-a2671e8e8f2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### concatenate the first and last name into one column and calcualte salary increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e37d21b-ec59-47d1-abe6-2f7c653e20e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat,concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bc78815-b83a-4242-b6d7-cda8fa6909bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36| 1609.695983886719|\n",
      "|   Emelyne Blaza|3006.04|3306.6440429687505|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36| 3917.496118164063|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|3819.8928710937503|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(concat_ws(' ', col(\"first_name\"), col(\"last_name\")).alias(\"full_name\"),\n",
    "                  col(\"salary\"), \n",
    "                (col(\"salary\")*1.1).alias(\"salary_increase\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b0f0b5b-26be-4547-bf79-1c89ea3e456f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36| 1609.695983886719|\n",
      "|   Emelyne Blaza|3006.04|3306.6440429687505|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36| 3917.496118164063|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|3819.8928710937503|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#USING EXPRESSION\n",
    "\n",
    "persons_df.select(concat_ws(' ', col(\"first_name\"), col(\"last_name\")).alias(\"full_name\"),\n",
    "                  col(\"salary\"), \n",
    "                  expr(\"salary *1.1\").alias(\"salary_increase\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c662d13d-dd9d-436c-8667-83581dbfbef5",
   "metadata": {},
   "source": [
    "## Filter and Where Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89ad462a-1d3f-411f-8f6f-467a9d3ba9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "persons_df.filter('salary <= 3000').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb7e9fac-f96f-4e98-8181-253981f0aec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where('salary <= 3000').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "530bf287-863b-439e-840a-b55c1b00528e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 16|   Margaux| Archbold|[And Now a Word f...|1013.75|http://dummyimage...|   1988-07-29|  true|\n",
      "| 26|     Clive|      Lax|             [Rabid]|2126.87|http://dummyimage...|   1981-10-26|  true|\n",
      "| 33|  Sherline|  Primett|   [Jungle Fighters]|2309.39|http://dummyimage...|   1972-07-23|  true|\n",
      "| 34|     Davis|    Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 37|    Carlen|  Sharply|[Dr. Jekyll and M...|2051.85|http://dummyimage...|   2002-06-01|  true|\n",
      "| 40|    Jordan|   Lorant|[Shockproof, Bach...|2183.91|http://dummyimage...|   1979-07-29|  true|\n",
      "| 49| Kendricks|      Kee|   [Flower & Garnet]|2304.39|http://dummyimage...|   1999-11-14|  true|\n",
      "| 57|   Krystle|  Shovell|[Doomsday, Flight...|2260.76|http://dummyimage...|   1987-09-01|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#two conditions using the where function\n",
    "persons_df.where((col('salary')<=3000) & (col(\"active\") == True)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40075d23-aa81-4453-bc5e-78eaba5c9321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eec5f4e2-3d85-4bde-8d5d-de9a625b73e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "| 25|     Kelcy|     Wogdon|    [Iron Mask, The]|4512.51|http://dummyimage...|   2000-10-20|  true|\n",
      "| 28|   Frankie|  Copestick|[Computer Wore Te...|1186.68|http://dummyimage...|   1994-03-09| false|\n",
      "| 32|      Redd|   Akenhead|[Century of the D...| 2470.9|http://dummyimage...|   2000-06-05| false|\n",
      "| 38|    Camile|       Mace|[Family Guy Prese...|3559.93|http://dummyimage...|   1994-12-12| false|\n",
      "| 48|Maximilian|      Jonin|[The Last Shark, ...|3274.34|http://dummyimage...|   1994-09-16| false|\n",
      "| 69|  Annabell|    Doughty|[Entertaining Ang...|2022.57|http://dummyimage...|   2000-09-03|  true|\n",
      "| 88|     Jobie|    Maughan|[Devils on the Do...| 3899.2|http://dummyimage...|   2000-02-07| false|\n",
      "| 95|      Cobb|    MacLure|[Storage 24, His ...|1621.17|http://dummyimage...|   1994-06-28| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.filter((year(\"date_of_birth\") == 2000) | (year(\"date_of_birth\") == 1994) ).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77f223ff-cc69-46d4-9312-c23ba88e1a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8e6260e-4663-4638-aff6-e7a8196b599c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| 11|   Timothy|   Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where(array_contains(persons_df.fav_movies, \"Land of the Lost\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9129285-277e-40c5-804c-b4880b4050f1",
   "metadata": {},
   "source": [
    "## Distinct, Drop duplicates and orderby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "022c9871-0a8f-45e7-b988-27fe007f054e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count,desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61a99b5a-14dc-4105-9e7c-002150fcb6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select('active').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f261c6e8-784a-4e99-9807-2a6adb9b9f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|       Sky|1971| false|\n",
      "|   Timothy|1971| false|\n",
      "|    Lucita|1972|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|     Toddy|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(persons_df.select(col('first_name'), year(col('date_of_birth')).alias('year'), col('active')).orderBy('year','first_name')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7f2572d-1dcd-4fc0-b384-4be9d6bec976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check if any records repeat themselves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c6eb4-a10e-4a53-8e42-92a420151836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a797c41d-d314-47ec-ab07-b2796a8cc4a8",
   "metadata": {},
   "source": [
    "## Rows and unions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbc53a57-bbce-4ce8-88a0-88a3a126d010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5a20b62-f844-4366-81f5-cba4b066d96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_person  = Row(101,\"robert\",\"jack\",['Men in black','X_men'],4300.64,\"http://someimage.com\",\"1995-08-14\",True)\n",
    "new_peron_list = [Row(102,\"daniel\",\"jonne\",['Men in black','X_men'],4300.64,\"http://someimage.com\",\"1995-08-14\",True),\n",
    "                  Row(103,\"ryan\",\"marris\",['Men in black','X_men'],4300.64,\"http://someimage.com\",\"1995-08-14\",True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eafb56f0-7a6f-4f39-a1f4-19f401129e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_peron_list.append(new_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e595d59c-4407-4620-990f-8e6318cae0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Row(102, 'daniel', 'jonne', ['Men in black', 'X_men'], 4300.64, 'http://someimage.com', '1995-08-14', True)>, <Row(103, 'ryan', 'marris', ['Men in black', 'X_men'], 4300.64, 'http://someimage.com', '1995-08-14', True)>, <Row(101, 'robert', 'jack', ['Men in black', 'X_men'], 4300.64, 'http://someimage.com', '1995-08-14', True)>]\n"
     ]
    }
   ],
   "source": [
    "print(new_peron_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba1ef9cc-69a9-4235-9db3-078d6f51967c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2286f144-3f6f-472e-b241-56a9a178dedd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = persons_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a2e9886-42a0-4962-a3d4-609feb0365cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_person_df = spark.createDataFrame(new_peron_list,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff6a8932-b55b-4d9f-b2d7-fe6b81b7249c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|102|    daniel|    jonne|[Men in black, X_...|4300.64|http://someimage.com|   1995-08-14|  true|\n",
      "|103|      ryan|   marris|[Men in black, X_...|4300.64|http://someimage.com|   1995-08-14|  true|\n",
      "|101|    robert|     jack|[Men in black, X_...|4300.64|http://someimage.com|   1995-08-14|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_person_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9b282a2-9694-455b-9d6d-e78fff3c9011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies|            salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "|103|      ryan|   marris|[Men in black, X_...|           4300.64|http://someimage.com|   1995-08-14|  true|\n",
      "|102|    daniel|    jonne|[Men in black, X_...|           4300.64|http://someimage.com|   1995-08-14|  true|\n",
      "|101|    robert|     jack|[Men in black, X_...|           4300.64|http://someimage.com|   1995-08-14|  true|\n",
      "|100|    Virgie| Domanski|[Horseman, The, S...| 2165.929931640625|http://dummyimage...|   2002-01-05|  true|\n",
      "| 99|   Rozalie|   Wannop|[Suddenly, The No...|1259.6400146484375|http://dummyimage...|   1997-03-25| false|\n",
      "| 98|     Davin|     Labb|[Viva Riva!, Kill...| 1452.739990234375|http://dummyimage...|   1988-01-27|  true|\n",
      "| 97|      Rodi|   Farnan|[Code, The (Menta...|   2325.8798828125|http://dummyimage...|   1972-01-04| false|\n",
      "| 96|       Dew| Coopland|              [Rush]|  2725.56005859375|http://dummyimage...|   1986-11-14| false|\n",
      "| 95|      Cobb|  MacLure|[Storage 24, His ...|1621.1700439453125|http://dummyimage...|   1994-06-28| false|\n",
      "| 94|    Bennie|   Knight|[House on Carroll...| 2370.239990234375|http://dummyimage...|   1977-08-27| false|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##We can combine new data to old using union\n",
    "\n",
    "add_person_df = persons_df.union(new_person_df)\n",
    "\n",
    "add_person_df.sort(desc('id')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28b406-d387-45ef-b085-72844b6c6bf7",
   "metadata": {},
   "source": [
    "## Adding renaming and dropping columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d447424-be2b-481a-b091-be1187514dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f0cc5a6-fe17-4f07-8d07-cf3e6f872837",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|   salary_increase|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true| 1609.695983886719|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|3306.6440429687505|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|1565.1680053710938|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true| 3917.496118164063|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|  5428.35712890625|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false| 1268.552978515625|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false| 1149.202978515625|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|1262.5360107421875|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|1190.3209838867188|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|3819.8928710937503|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_person_df1 = persons_df.withColumn(\"salary_increase\", expr(\"salary*1.1\"))\n",
    "aug_person_df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd160b87-6675-47ae-b870-2fb644d81ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'first_name',\n",
       " 'last_name',\n",
       " 'fav_movies',\n",
       " 'salary',\n",
       " 'image_url',\n",
       " 'date_of_birth',\n",
       " 'active',\n",
       " 'salary_increase']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_person_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f984e1fd-ad48-47ff-962b-c7430115811a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract the year from DOB and rename fav movies and dropped salary increase\n",
    "\n",
    "aug_person_df2 = (aug_person_df1\n",
    "                  .withColumn(\"birth_year\",year(\"date_of_birth\"))\n",
    "                  .withColumnRenamed(\"fav_movies\",\"movies\")\n",
    "                  .withColumn(\"salary_x10\",round(col(\"salary_increase\"),2))\n",
    "                  .drop(\"salary_increase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbb35f2e-6998-4b6b-99e2-644ae1e70a55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "| id|first_name|last_name|              movies| salary|           image_url|date_of_birth|active|birth_year|salary_x10|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|      1991|    1609.7|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|      1991|   3306.64|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|      1990|   1565.17|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|      1987|    3917.5|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|      1992|   5428.36|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|      1986|   1268.55|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|      1971|    1149.2|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|      1973|   1262.54|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|      1974|   1190.32|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|      1997|   3819.89|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_person_df2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a110412-d6d8-4295-b238-cb73e126a926",
   "metadata": {},
   "source": [
    "## Working with missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5db89b1-e438-4558-8fe5-5f5a2040d649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_movies_list = [Row(None, None, None),\n",
    "                   Row(None, None, 2020),\n",
    "                   Row(\"John Doe\", \"Awesome Movie\", None),\n",
    "                   Row(None, \"Awesome Movie\", 2021),\n",
    "                   Row(\"Mary Jane\", None, 2019),\n",
    "                   Row(\"Vikter Duplaix\", \"Not another teen movie\", 2001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7634b49e-f1e5-4524-9953-1ead1e147adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row(None, None, None)>,\n",
       " <Row(None, None, 2020)>,\n",
       " <Row('John Doe', 'Awesome Movie', None)>,\n",
       " <Row(None, 'Awesome Movie', 2021)>,\n",
       " <Row('Mary Jane', None, 2019)>,\n",
       " <Row('Vikter Duplaix', 'Not another teen movie', 2001)>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0126322d-dd90-4b92-9265-42179df8c622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_movies_columns = ['actor_name','movie_title','produced_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80471986-cf7a-461e-9d82-643aae350036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_movies_df = spark.createDataFrame(bad_movies_list,bad_movies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ab0a1d4-bada-4ed1-b634-d1882b256e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+-------------+\n",
      "|actor_name    |movie_title           |produced_year|\n",
      "+--------------+----------------------+-------------+\n",
      "|null          |null                  |null         |\n",
      "|null          |null                  |2020         |\n",
      "|John Doe      |Awesome Movie         |null         |\n",
      "|null          |Awesome Movie         |2021         |\n",
      "|Mary Jane     |null                  |2019         |\n",
      "|Vikter Duplaix|Not another teen movie|2001         |\n",
      "+--------------+----------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c967818-1091-417a-a98a-a112db3c6e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop rows with any null values \n",
    "bad_movies_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57c423b7-08a4-451f-8e3d-c9fb7e6e632e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop rows with any null values \n",
    "bad_movies_df.na.drop(\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56ccabab-5111-410f-bf94-49287181416d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|          null|                null|         2020|\n",
      "|      John Doe|       Awesome Movie|         null|\n",
      "|          null|       Awesome Movie|         2021|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop rows with all null values for all columns\n",
    "bad_movies_df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7484350c-8832-4aa7-be3c-cbb15dfe41ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|      John Doe|       Awesome Movie|         null|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtered df for where actor name is not null\n",
    "bad_movies_df.filter(col(\"actor_name\")!= 'null').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "019d1e1d-2cf5-4f16-8eae-b887bf367867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|      John Doe|       Awesome Movie|         null|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtered df for where actor name is not null\n",
    "bad_movies_df.filter(col(\"actor_name\").isNull() != True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e20a8d5a-2fa2-4fc3-a47d-415c7dc4ea9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|    produced_year|\n",
      "+-------+-----------------+\n",
      "|  count|                4|\n",
      "|   mean|          2015.25|\n",
      "| stddev|9.535023160258536|\n",
      "|    min|             2001|\n",
      "|    max|             2021|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "##summary of columns in a df using describe \n",
    "\n",
    "bad_movies_df.describe(\"produced_year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5ed0e25-2bad-4a53-9681-ecb081dfd95a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|summary|    actor_name|\n",
      "+-------+--------------+\n",
      "|  count|             3|\n",
      "|   mean|          null|\n",
      "| stddev|          null|\n",
      "|    min|      John Doe|\n",
      "|    max|Vikter Duplaix|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bad_movies_df.describe(\"actor_name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc8161-2581-4606-b72d-277f11dd9f05",
   "metadata": {},
   "source": [
    "## creating spark functions to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e84bb81f-b50a-4c38-80cf-97fc8aa83fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "780209dd-4b2d-484a-a502-865ef2efc151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "student_list = [(\"joe\",90),\n",
    "                (\"jack\",95),\n",
    "                (\"jill\",100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42d7b216-f993-4378-aab5-e298f6ea548e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "student_cols = [\"name\",\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "212e2068-e385-42a6-9227-5e37669f86fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "student_df = spark.createDataFrame(student_list,student_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc216c36-d914-493c-a9cf-96244f53e5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|score|\n",
      "+----+-----+\n",
      "| joe|   90|\n",
      "|jack|   95|\n",
      "|jill|  100|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854a3b0-7f8e-4889-9769-de15a46b34ce",
   "metadata": {},
   "source": [
    "#### Create a pyhton function called letter grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5722683-1748-4ed9-850d-99b5b5ff81d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lettergrade(score:int):\n",
    "    \n",
    "    grade = \"\"\n",
    "    \n",
    "    if score > 100:\n",
    "        grade = \"cheating\"\n",
    "        \n",
    "    elif score >=90:\n",
    "        grade = \"A\"\n",
    "        \n",
    "    elif score >=80:\n",
    "        grade = \"B\"\n",
    "        \n",
    "    elif score >=70:\n",
    "        grade = \"C\"\n",
    "        \n",
    "    else:\n",
    "        grade = \"F\"\n",
    "    \n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cffd3e05-eb91-4355-87b9-4ffbe4f0d56d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n"
     ]
    }
   ],
   "source": [
    "print(lettergrade(56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "087549ed-dd9a-4890-95fd-ac3b5b0603e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert thid function to a udf\n",
    "#the Udf are poorly optimized and should be avooided as much as possible\n",
    "lettergradeudf = udf(lettergrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d41d2912-5bac-434b-965a-c7492a6975c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:>                                                         (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|name|score|grade|\n",
      "+----+-----+-----+\n",
      "| joe|   90|    A|\n",
      "|jack|   95|    A|\n",
      "|jill|  100|    A|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "student_df.select(\"name\",\"score\", lettergradeudf(col(\"score\")).alias(\"grade\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e397e91-3df8-482e-8ba1-ff074d97d647",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bca4e33d-8016-4d92-843b-cb0dd39a4509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = \"./data/flights/flight-summary.csv\"\n",
    "\n",
    "flights_df = (spark.read.format(\"csv\")\n",
    "              .option('header',True)\n",
    "              .option('inferSchema',True)\n",
    "              .load(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cbf7142e-f8ed-4c8c-9cc9-6d3d4fd6b1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4693"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e71346fb-d837-4777-a048-14d87f6b1b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+-----+\n",
      "|origin_code|origin_airport                                  |origin_city |origin_state|dest_code|dest_airport                                |dest_city       |dest_state|count|\n",
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+-----+\n",
      "|BQN        |Rafael Hernández Airport                        |Aguadilla   |PR          |MCO      |Orlando International Airport               |Orlando         |FL        |441  |\n",
      "|PHL        |Philadelphia International Airport              |Philadelphia|PA          |MCO      |Orlando International Airport               |Orlando         |FL        |4869 |\n",
      "|MCI        |Kansas City International Airport               |Kansas City |MO          |IAH      |George Bush Intercontinental Airport        |Houston         |TX        |1698 |\n",
      "|SPI        |Abraham Lincoln Capital Airport                 |Springfield |IL          |ORD      |Chicago O'Hare International Airport        |Chicago         |IL        |998  |\n",
      "|SNA        |John Wayne Airport (Orange County Airport)      |Santa Ana   |CA          |PHX      |Phoenix Sky Harbor International Airport    |Phoenix         |AZ        |3846 |\n",
      "|LBB        |Lubbock Preston Smith International Airport     |Lubbock     |TX          |DEN      |Denver International Airport                |Denver          |CO        |618  |\n",
      "|ORD        |Chicago O'Hare International Airport            |Chicago     |IL          |PDX      |Portland International Airport              |Portland        |OR        |2149 |\n",
      "|EWR        |Newark Liberty International Airport            |Newark      |NJ          |STT      |Cyril E. King Airport                       |Charlotte Amalie|VI        |239  |\n",
      "|ATL        |Hartsfield-Jackson Atlanta International Airport|Atlanta     |GA          |GSP      |Greenville-Spartanburg International Airport|Greer           |SC        |2470 |\n",
      "|MCI        |Kansas City International Airport               |Kansas City |MO          |MKE      |General Mitchell International Airport      |Milwaukee       |WI        |612  |\n",
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a371b84-5bb2-4fa7-a76c-5f07e6bb83e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin_code: string (nullable = true)\n",
      " |-- origin_airport: string (nullable = true)\n",
      " |-- origin_city: string (nullable = true)\n",
      " |-- origin_state: string (nullable = true)\n",
      " |-- dest_code: string (nullable = true)\n",
      " |-- dest_airport: string (nullable = true)\n",
      " |-- dest_city: string (nullable = true)\n",
      " |-- dest_state: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64c32981-0f60-4c91-b48b-af139a24f308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flights_df = (flights_df\n",
    "             .withColumnRenamed(\"count\", \"flight_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "990a6e08-b88b-41c2-bd08-2cb530a26467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+------------+---------+--------------------+----------------+----------+------------+\n",
      "|origin_code|      origin_airport| origin_city|origin_state|dest_code|        dest_airport|       dest_city|dest_state|flight_count|\n",
      "+-----------+--------------------+------------+------------+---------+--------------------+----------------+----------+------------+\n",
      "|        BQN|Rafael Hernández ...|   Aguadilla|          PR|      MCO|Orlando Internati...|         Orlando|        FL|         441|\n",
      "|        PHL|Philadelphia Inte...|Philadelphia|          PA|      MCO|Orlando Internati...|         Orlando|        FL|        4869|\n",
      "|        MCI|Kansas City Inter...| Kansas City|          MO|      IAH|George Bush Inter...|         Houston|        TX|        1698|\n",
      "|        SPI|Abraham Lincoln C...| Springfield|          IL|      ORD|Chicago O'Hare In...|         Chicago|        IL|         998|\n",
      "|        SNA|John Wayne Airpor...|   Santa Ana|          CA|      PHX|Phoenix Sky Harbo...|         Phoenix|        AZ|        3846|\n",
      "|        LBB|Lubbock Preston S...|     Lubbock|          TX|      DEN|Denver Internatio...|          Denver|        CO|         618|\n",
      "|        ORD|Chicago O'Hare In...|     Chicago|          IL|      PDX|Portland Internat...|        Portland|        OR|        2149|\n",
      "|        EWR|Newark Liberty In...|      Newark|          NJ|      STT|Cyril E. King Air...|Charlotte Amalie|        VI|         239|\n",
      "|        ATL|Hartsfield-Jackso...|     Atlanta|          GA|      GSP|Greenville-Sparta...|           Greer|        SC|        2470|\n",
      "|        MCI|Kansas City Inter...| Kansas City|          MO|      MKE|General Mitchell ...|       Milwaukee|        WI|         612|\n",
      "+-----------+--------------------+------------+------------+---------+--------------------+----------------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b2809-3969-4ea4-82c5-24b3a5c205c1",
   "metadata": {},
   "source": [
    "### Count(col) and count distinct(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6cc1fc04-6477-4f0b-99d2-e4751cde7bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count,count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b6a0905-51a8-496a-b693-faf67603abdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+\n",
      "|count(origin_airport)|count(dest_airport)|\n",
      "+---------------------+-------------------+\n",
      "|                 4693|               4693|\n",
      "+---------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#count for origin and origin airport count excludes null values\n",
    "\n",
    "flights_df.select(count('origin_airport'),count('dest_airport')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0701cc0-d297-4032-b231-caae0b9958b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|          null|                null|         null|\n",
      "|          null|                null|         2020|\n",
      "|      John Doe|       Awesome Movie|         null|\n",
      "|          null|       Awesome Movie|         2021|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1fb04852-dc69-4e98-bdb4-c9da9a6f8fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+--------------------+\n",
      "|count(movie_title)|count(actor_name)|count(produced_year)|\n",
      "+------------------+-----------------+--------------------+\n",
      "|                 3|                3|                   4|\n",
      "+------------------+-----------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bad_movies_df.select(count(\"movie_title\"),count(\"actor_name\"),count(\"produced_year\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9864742-c0bf-4d31-9fac-818434dffdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------------------------+------------+\n",
      "|count(DISTINCT origin_airport)|count(DISTINCT dest_airport)|total_number|\n",
      "+------------------------------+----------------------------+------------+\n",
      "|                           322|                         322|        4693|\n",
      "+------------------------------+----------------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#to get the number of unique values in the column\n",
    "flights_df.select(count_distinct('origin_airport'),count_distinct('dest_airport'), count(\"*\").alias('total_number')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df865c65-cf2e-46ba-a38d-3b209267d5a1",
   "metadata": {},
   "source": [
    "### min(col), max(col), sum(col), sum distinct(col), avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fa2c5dcc-3371-4574-b61c-3e273e1502b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min,max,sum, sum_distinct,avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "10570314-bbd9-4cbc-b386-e49b98fd7044",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|min(flight_count)|max(flight_count)|\n",
      "+-----------------+-----------------+\n",
      "|                1|            13744|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#shows the busiest flight route\n",
    "flights_df.select(min(col(\"flight_count\")), max(col(\"flight_count\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "935339ef-9427-4034-ae8b-e57b2d40debd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(flight_count)|\n",
      "+-----------------+\n",
      "|          5332914|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sum of flight counts\n",
    "flights_df.select(sum(col(\"flight_count\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "963b3183-74f0-4da2-9d68-dfe95ba9f2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|sum(DISTINCT flight_count)|\n",
      "+--------------------------+\n",
      "|                   3612257|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select(sum_distinct(col(\"flight_count\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "462fa323-a9ec-4404-838e-e3a205cb72ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------------------+-------------+------------+---------+---------------------------------+-----------+----------+------------+\n",
      "|origin_code|origin_airport                     |origin_city  |origin_state|dest_code|dest_airport                     |dest_city  |dest_state|flight_count|\n",
      "+-----------+-----------------------------------+-------------+------------+---------+---------------------------------+-----------+----------+------------+\n",
      "|SFO        |San Francisco International Airport|San Francisco|CA          |LAX      |Los Angeles International Airport|Los Angeles|CA        |13744       |\n",
      "+-----------+-----------------------------------+-------------+------------+---------+---------------------------------+-----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find the flight route thats is the busiest\n",
    "flights_df.where(col(\"flight_count\") == 13744).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4137dbf6-7688-4174-b71b-8be4e9f34e39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "| avg(flight_count)|\n",
      "+------------------+\n",
      "|1136.3549968037503|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#average flight count\n",
    "flights_df.select(avg(col(\"flight_count\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da62d2-a40a-417c-a6ba-f1c087f25c1f",
   "metadata": {},
   "source": [
    "### Agregations with grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c3736a25-4d1f-42fd-82dc-68d5bef9be47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+-----+\n",
      "|origin_airport                                  |count|\n",
      "+------------------------------------------------+-----+\n",
      "|Hartsfield-Jackson Atlanta International Airport|169  |\n",
      "|Chicago O'Hare International Airport            |162  |\n",
      "|Dallas/Fort Worth International Airport         |148  |\n",
      "|Denver International Airport                    |139  |\n",
      "|Minneapolis-Saint Paul International Airport    |120  |\n",
      "+------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.groupBy(\"origin_airport\").count().orderBy(\"count\", ascending=False).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c9821e60-3926-45c6-bcd7-e647d2824839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+----------------+\n",
      "|origin_airport                                                        |max_flight_count|\n",
      "+----------------------------------------------------------------------+----------------+\n",
      "|San Francisco International Airport                                   |13744           |\n",
      "|Los Angeles International Airport                                     |13457           |\n",
      "|John F. Kennedy International Airport (New York International Airport)|12016           |\n",
      "|McCarran International Airport                                        |9715            |\n",
      "|LaGuardia Airport (Marine Air Terminal)                               |9639            |\n",
      "+----------------------------------------------------------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find the maxinmun flight count per each origin airport in descending order\n",
    "(flights_df.groupBy(\"origin_airport\")\n",
    "          .agg(max(\"flight_count\").alias(\"max_flight_count\"))\n",
    "          .orderBy(\"max_flight_count\", ascending=False)).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7ff6645e-5b5d-4c9d-8b23-92949976fbd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----+\n",
      "|origin_state|origin_city  |count|\n",
      "+------------+-------------+-----+\n",
      "|CA          |San Francisco|80   |\n",
      "|CA          |Los Angeles  |80   |\n",
      "|CA          |San Diego    |47   |\n",
      "|CA          |Oakland      |35   |\n",
      "|CA          |Sacramento   |27   |\n",
      "|CA          |San Jose     |25   |\n",
      "|CA          |Santa Ana    |22   |\n",
      "|CA          |Ontario      |14   |\n",
      "|CA          |Long Beach   |12   |\n",
      "|CA          |Palm Springs |12   |\n",
      "+------------+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count of records associated with the city of califronia grouped by city\n",
    "\n",
    "(flights_df.groupBy(\"origin_state\", \"origin_city\")\n",
    "           .count()\n",
    "           .where(col(\"origin_state\")==\"CA\")\n",
    "           .orderBy(\"count\",ascending=False)\n",
    ").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b75281a6-06f4-4a75-ad22-3ac7e45dd0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "|origin_airport                                   |max(flight_count)|min(flight_count)|sum(flight_count)|count(flight_count)|\n",
      "+-------------------------------------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "|Melbourne International Airport                  |1332             |1332             |1332             |1                  |\n",
      "|San Diego International Airport (Lindbergh Field)|6942             |4                |70207            |46                 |\n",
      "|Eppley Airfield                                  |2083             |1                |16753            |21                 |\n",
      "|Kahului Airport                                  |8313             |67               |20627            |18                 |\n",
      "|Austin-Bergstrom International Airport           |4674             |8                |42067            |41                 |\n",
      "+-------------------------------------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MULTIPLE AGGREGATIONS FOR A SINGLE COLUMN \n",
    "\n",
    "(flights_df.groupBy(\"origin_airport\")\n",
    "          .agg(max(\"flight_count\"),\n",
    "               min(\"flight_count\"),\n",
    "               sum(\"flight_count\"),\n",
    "               count(\"flight_count\"))).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ce995-b2f1-4703-9dc1-4dd803274c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
